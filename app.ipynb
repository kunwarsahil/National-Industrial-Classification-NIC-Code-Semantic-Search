{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d1b4947-b9e3-442f-9416-753bcbc3213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi\n",
      "  Using cached fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn\n",
      "  Using cached uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\avnex\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\avnex\\anaconda3\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\avnex\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\avnex\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: ollama in c:\\users\\avnex\\anaconda3\\lib\\site-packages (0.4.7)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi)\n",
      "  Using cached starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from fastapi) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from fastapi) (4.12.2)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\avnex\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Using cached fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
      "Using cached uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading faiss_cpu-1.10.0-cp312-cp312-win_amd64.whl (13.7 MB)\n",
      "   ---------------------------------------- 0.0/13.7 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.8/13.7 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.2/13.7 MB 11.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.3/13.7 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.3/13.7 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.7/13.7 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.8/13.7 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.6/13.7 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.7/13.7 MB 9.0 MB/s eta 0:00:00\n",
      "Using cached starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "Installing collected packages: faiss-cpu, uvicorn, starlette, fastapi\n",
      "Successfully installed faiss-cpu-1.10.0 fastapi-0.115.11 starlette-0.46.1 uvicorn-0.34.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi uvicorn faiss-cpu torch transformers pandas numpy ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f5a1e3b-30b3-4aef-ae36-f4ee9d47f373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook app.ipynb to script\n",
      "[NbConvertApp] Writing 4005 bytes to app.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script app.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29009af-ca4b-454b-a456-8c434f749f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Faiss index loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [42500]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:9040 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:61463 - \"OPTIONS /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:61463 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:61464 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:61494 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:61521 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:61526 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:61543 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:61555 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:61560 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:61577 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:61598 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:61604 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53569 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53580 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53587 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53644 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53750 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53756 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53761 - \"POST /search HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import ollama\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "\n",
    "\n",
    "# --- Initialize FastAPI ---\n",
    "app = FastAPI()\n",
    "\n",
    "# --- Load Faiss Index ---\n",
    "index_path = r\"C:\\Users\\avnex\\OneDrive\\Desktop\\modernbert_faiss_index.bin\"  \n",
    "if os.path.exists(index_path):\n",
    "    en_index = faiss.read_index(index_path)\n",
    "    print(\"✅ Faiss index loaded successfully!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"❌ Index file not found at {index_path}\")\n",
    "\n",
    "# --- Load Dataset (Metadata) ---\n",
    "df = pd.read_csv(r\"C:\\Users\\avnex\\OneDrive\\Desktop\\combined.csv\")\n",
    "\n",
    "# --- Load ModernBERT Model ---\n",
    "model_id = \"nomic-ai/modernbert-embed-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "modernbert_model = AutoModel.from_pretrained(model_id)\n",
    "\n",
    "# --- Translation Function (Using Ollama Llama3.2) ---\n",
    "MODEL_NAME = \"llama3.2:latest\"\n",
    "\n",
    "def translate_to_english(text: str) -> str:\n",
    "    \"\"\"Translates input text to English while preserving semantic meaning.\"\"\"\n",
    "    prompt = f\"Convert the following text to English while preserving the semantic meaning, don't give an explanation:\\n\\n{text}\"\n",
    "    response = ollama.chat(\n",
    "        model=MODEL_NAME, \n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response['message']['content'].strip()\n",
    "\n",
    "# --- Embedding Function ---\n",
    "def get_modernbert_embedding(text: str):\n",
    "    \"\"\"Encodes a query using ModernBERT.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = modernbert_model(**inputs)\n",
    "    emb = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    return emb[0].astype(\"float32\")\n",
    "\n",
    "# --- Semantic Search Function ---\n",
    "def semantic_search(query_vector, k=5):\n",
    "    \"\"\"Searches the Faiss index for the k nearest neighbors.\"\"\"\n",
    "    query_vector = query_vector.reshape(1, -1)\n",
    "    faiss.normalize_L2(query_vector)\n",
    "    distances, indices = en_index.search(query_vector, k)\n",
    "    \n",
    "    results = df.iloc[indices[0]][[\"S.No.\", \"Description\", \"Class\", \"Group\", \"Sub Class\"]].to_dict(orient=\"records\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# --- Define API Request Model ---\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "    k: int = 5\n",
    "\n",
    "# --- Search Endpoint ---\n",
    "@app.post(\"/search\")\n",
    "async def search(request: QueryRequest):\n",
    "    \"\"\"Performs a semantic search based on the user's input query.\"\"\"\n",
    "    try:\n",
    "        query_text = translate_to_english(request.query)  # Translate query to English\n",
    "        query_vector = get_modernbert_embedding(query_text)  # Get embedding\n",
    "        results = semantic_search(query_vector, request.k)  # Get top-k results\n",
    "        \n",
    "        return {\"query\": request.query, \"translated_query\": query_text, \"results\": results}\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# --- Root Endpoint ---\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"Welcome to the Semantic Search API!\"}\n",
    "# Add CORS middleware to allow frontend to access the API\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://127.0.0.1:5500\"],  # Allow requests from your frontend\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],  # Allow all HTTP methods (GET, POST, etc.)\n",
    "    allow_headers=[\"*\"],  # Allow all headers\n",
    ")\n",
    "\n",
    "\n",
    "# --- Run FastAPI Inside Jupyter ---\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=9040)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851212dc-a808-4fa1-b75d-5360cf1fabee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
